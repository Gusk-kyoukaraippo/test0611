import streamlit as st
import pandas as pd
from llama_index.core import VectorStoreIndex, Document, QueryBundle
from llama_index.retrievers.bm25 import BM25Retriever
from llama_index.core.retrievers import BaseRetriever
from llama_index.core.schema import NodeWithScore
from llama_index.core import get_response_synthesizer
from llama_index.llms.google_genai import GoogleGenAI
from llama_index.embeddings.openai import OpenAIEmbedding # â˜…ã“ã“ã‚’OpenAIEmbeddingã«å¤‰æ›´
from typing import List, Dict, Any, Set
import sys
import os
import re

# --- Streamlit ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ ---
st.set_page_config(page_title="RAGãƒ™ãƒ¼ã‚¹ã®è³ªå•æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ", layout="wide")

st.title("ğŸ“š RAGãƒ™ãƒ¼ã‚¹ã®è³ªå•æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ")
st.markdown("ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã€åŒ—æµ·é“ã¨æ²–ç¸„ã‚’ç­”ãˆã¨ã™ã‚‹è³ªå•ãŒ200å…¥ã£ã¦ã„ã¾ã™ã€‚<br>"
            "ã‚ãªãŸã®å…¥åŠ›ã«åŸºã¥ã„ã¦æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„**è³ªå•**ã‚’æ¤œç´¢ã—ã€è³ªå•ã¨å›ç­”ã‚’æç¤ºã—ã¾ã™ã€‚")

# JavaScriptã§ãƒšãƒ¼ã‚¸ã‚’ä¸€ç•ªä¸Šã¾ã§ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã™ã‚‹é–¢æ•° (st.session_state ã¨é€£æº)
def scroll_to_top_conditional():
    if st.session_state.get('should_scroll_to_top', False):
        js_code = """
        <script>
            window.scrollTo({top: 0, behavior: 'smooth'});
        </script>
        """
        st.components.v1.html(js_code, height=0, width=0)
        st.session_state.should_scroll_to_top = False # ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å®Ÿè¡Œå¾Œã€ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ

# ã‚¢ãƒ—ãƒªã®ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã‚µã‚¤ã‚¯ãƒ«ã®æ—©ã„æ®µéšã§ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãƒã‚§ãƒƒã‚¯é–¢æ•°ã‚’å‘¼ã³å‡ºã™
# ã“ã‚Œã«ã‚ˆã‚Šã€UIã®æ›´æ–°å‰ã«ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãŒãƒˆãƒªã‚¬ãƒ¼ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒé«˜ã¾ã‚‹
scroll_to_top_conditional()

# --- ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®RAGSystemã‚¯ãƒ©ã‚¹ã‚’Streamlitã‚¢ãƒ—ãƒªã«çµ±åˆ ---
class RAGSystem:
    """
    RAG (Retrieval Augmented Generation) ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè£…ã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚
    CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã¨BM25æ¤œç´¢ã‚’çµ„ã¿åˆã‚ã›ã¦æƒ…å ±ã‚’å–å¾—ã—ã€
    Gemini LLMã‚’ç”¨ã„ã¦æœ€çµ‚çš„ãªå›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    """
    def __init__(self, config: Dict[str, Any]):
        """
        RAGSystemã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚
        """
        self.config = config
        self.documents: List[Document] = []
        self.document_map: Dict[str, Document] = {} 
        self.vector_retriever: BaseRetriever = None
        self.bm25_retriever: BM25Retriever = None
        self.response_synthesizer: Any = None
        self.llm: GoogleGenAI = None
        self.embed_model: OpenAIEmbedding = None # OpenAIEmbeddingã‚’è¿½åŠ 

        self._initialize_system()

    def _initialize_system(self):
        """
        RAGã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ã—ã€å¿…è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã¾ã™ã€‚
        """
        gemini_api_key = "GEMINI_API_KEY" # ã‚ãªãŸã®APIã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„
        openai_api_key = "OPENAI_API_KEY"
        self.config["gemini_api_key"] = gemini_api_key
        self.config["openai_api_key"] = openai_api_key


        self.documents = self._load_documents_from_csv(self.config["csv_file_path"])
        
        self.document_map = {doc.id_: doc for doc in self.documents}

        if not self.documents:
            st.error("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ãªã„ãŸã‚ã€ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚")
            st.stop()
            
        

        # --- OpenAI text-embedding-3-small ã‚’åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦è¨­å®š ---
        # model_name='text-embedding-3-small' ã‚’æŒ‡å®šã—ã¾ã™
        self.embed_model = OpenAIEmbedding(
            api_key=openai_api_key,
            model_name='text-embedding-3-small' 
        )
        # --- åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’VectorStoreIndexã«æ¸¡ã™ ---
        vector_index = VectorStoreIndex.from_documents(
            self.documents,
            embed_model=self.embed_model # ã“ã“ã§OpenAIã®åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®š
        )
        self.vector_retriever = vector_index.as_retriever(similarity_top_k=self.config["vector_top_k"])

        self.bm25_retriever = BM25Retriever.from_defaults(
            nodes=self.documents,
            similarity_top_k=self.config["bm25_top_k"]
        )

        self.llm = GoogleGenAI(
            api_key=self.config["gemini_api_key"],
            model=self.config["gemini_model_name"]
        )
        
        self.response_synthesizer = get_response_synthesizer(
            llm=self.llm,
            response_mode="compact"
        )

    def _load_documents_from_csv(self, file_path: str) -> List[Document]:
        """
        æŒ‡å®šã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿ã€LlamaIndexã®Documentã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆã‚’è¿”ã—ã¾ã™ã€‚
        """
        documents: List[Document] = []
        if not os.path.exists(file_path):
            st.error(f"ã‚¨ãƒ©ãƒ¼: '{file_path}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            st.stop()

        try:
            df = pd.read_csv(file_path)
            required_columns = ['id', 'question', 'answer', 'image_path']
            if not all(col in df.columns for col in required_columns):
                missing_cols = [col for col in required_columns if col not in df.columns]
                st.error(f"ã‚¨ãƒ©ãƒ¼: CSVã«å¿…è¦ãªã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ¬ ã‘ã¦ã„ã‚‹ã‚«ãƒ©ãƒ : {', '.join(missing_cols)}")
                st.stop()

            for _, row in df.iterrows():
                doc = Document(
                    text=row['question'],
                    metadata={
                        "answer": row['answer'],
                        "image": row['image_path']
                    },
                    id_=str(row['id'])
                )
                documents.append(doc)
        except pd.errors.EmptyDataError:
            st.warning(f"è­¦å‘Š: '{file_path}' ã¯ç©ºã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ã™ã€‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯èª­ã¿è¾¼ã¾ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
        except Exception as e:
            st.error(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.stop()
        return documents

    def query(self, query_text: str) -> Dict[str, Any]:
        """
        ä¸ãˆã‚‰ã‚ŒãŸã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦æ¤œç´¢ã‚’å®Ÿè¡Œã—ã€LLMã«æœ€é©ãªè³ªå•ã‚’é¸ã°ã›ã¾ã™ã€‚
        LLMãŒè³ªå•ã‚’é¸ã³ãã‚Œãªã‹ã£ãŸå ´åˆã¯ã€æ¤œç´¢çµæœã®æœ€åˆã®ï¼ˆæœ€ã‚‚ã‚¹ã‚³ã‚¢ã®é«˜ã„ï¼‰è³ªå•ã‚’è¿”ã—ã¾ã™ã€‚
        """
        query_bundle = QueryBundle(query_str=query_text)

        with st.spinner("æƒ…å ±ã‚’æ¤œç´¢ä¸­..."):
            vector_nodes = self.vector_retriever.retrieve(query_bundle)
            bm25_nodes = self.bm25_retriever.retrieve(query_bundle)

        combined_nodes: List[NodeWithScore] = []
        seen_node_ids: Set[str] = set()

        all_retrieved_nodes_unsorted = vector_nodes + bm25_nodes
        all_retrieved_nodes_unsorted.sort(key=lambda x: x.score if x.score is not None else -1, reverse=True)

        for node in all_retrieved_nodes_unsorted:
            if node.node_id not in seen_node_ids:
                combined_nodes.append(node)
                seen_node_ids.add(node.node_id)
        
        if not combined_nodes:
            st.warning("é–¢é€£ã™ã‚‹è³ªå•ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return {
                "selected_question_id": None,
                "retrieved_nodes": [],
                "llm_response_text": "é–¢é€£ã™ã‚‹è³ªå•ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
            }

        context_str = ""
        for i, node in enumerate(combined_nodes):
            context_str += f"--- è³ªå• {i+1} (ID: {node.node_id}) ---\n"
            context_str += f"è³ªå•å†…å®¹: {node.get_content()}\n"
            context_str += f"é–¢é€£ã™ã‚‹å›ç­”: {node.metadata.get('answer', 'N/A')}\n\n"

        llm_query_prompt = f"""
ä»¥ä¸‹ã®æ¤œç´¢çµæœã®ä¸­ã‹ã‚‰ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒªã«æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„ã€Œè³ªå•ã€ã®IDã‚’1ã¤ã ã‘é¸ã‚“ã§ãã ã•ã„ã€‚
å¿…ãšã€æœ€ã‚‚å¦¥å½“ã ã¨æ€ã‚ã‚Œã‚‹è³ªå•ã®IDã‚’1ã¤å›ç­”ã—ã¦ãã ã•ã„ã€‚
é¸æŠè‚¢ãŒãªã„å ´åˆã§ã‚‚ã€ç„¡ç†ã«ã§ã‚‚1ã¤é¸ã‚“ã§ãã ã•ã„ã€‚
å›ç­”ã¯ã€é¸ã‚“ã è³ªå•ã®IDã®ã¿ã‚’æ­£ç¢ºã«è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚IDä»¥å¤–ã¯ä¸€åˆ‡å«ã‚ãªã„ã§ãã ã•ã„ã€‚

--- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒª ---
{query_text}

--- æ¤œç´¢çµæœ ---
{context_str}

--- ã‚ãªãŸã®å›ç­” (é¸ã‚“ã è³ªå•ã®IDã€ä¾‹: "123" ã¾ãŸã¯ "71e4f049-0fe7-4766-9c68-2c11dcc97e95") ---
"""
        with st.spinner("LLMãŒæœ€é©ãªè³ªå•ã‚’é¸æŠä¸­..."):
            llm_response = self.llm.complete(llm_query_prompt)
        
        raw_llm_response_text = str(llm_response).strip()
        
        uuid_pattern = r'[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}'
        match = re.search(uuid_pattern, raw_llm_response_text)
        
        if not match:
            match = re.search(r'\d+', raw_llm_response_text)

        selected_id = match.group(0) if match else None

        combined_node_ids = {node.node_id for node in combined_nodes}

        if selected_id is None or selected_id not in combined_node_ids:
            st.warning("LLMã¯æœ‰åŠ¹ãªè³ªå•IDã‚’é¸ã³ã¾ã›ã‚“ã§ã—ãŸã€‚æ¤œç´¢çµæœã®æœ€åˆã®è³ªå•ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¨ã—ã¦é¸æŠã—ã¾ã™ã€‚")
            selected_id = combined_nodes[0].node_id
        
        return {
            "selected_question_id": selected_id,
            "retrieved_nodes": combined_nodes,
            "llm_response_text": raw_llm_response_text
        }


# --- è¨­å®šå€¤ ---
CONFIG: Dict[str, Any] = {
    "csv_file_path": 'dummy2.csv', 
    "vector_top_k": 3, 
    "bm25_top_k": 3, 
    "gemini_model_name": "gemini-2.0-flash" 
}

@st.cache_resource
def get_rag_system():
    try:
        rag_system = RAGSystem(CONFIG)
        return rag_system
    except SystemExit:
        st.error("RAGã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ä¸­ã«è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚„APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    except Exception as e:
        st.error(f"RAGã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.stop()

rag_system = get_rag_system()

st.divider()

# st.session_state ã®åˆæœŸåŒ–
if 'current_query' not in st.session_state:
    st.session_state.current_query = ""
if 'show_input_section' not in st.session_state:
    st.session_state.show_input_section = True 
if 'last_result' not in st.session_state:
    st.session_state.last_result = None 
if 'display_node_id' not in st.session_state:
    st.session_state.display_node_id = None 
if 'should_scroll_to_top' not in st.session_state:
    st.session_state.should_scroll_to_top = False 
if 'user_entered_query' not in st.session_state: # æ–°ã—ãè¿½åŠ 
    st.session_state.user_entered_query = ""

# æ–°ã—ã„æ¤œç´¢ã‚’é–‹å§‹ã™ã‚‹é–¢æ•°
def reset_search():
    st.session_state.current_query = ""
    st.session_state.show_input_section = True
    st.session_state.last_result = None 
    st.session_state.display_node_id = None 
    st.session_state.should_scroll_to_top = True 
    st.session_state.user_entered_query = "" # ãƒªã‚»ãƒƒãƒˆæ™‚ã«ã‚‚ã‚¯ãƒªã‚¢
    st.rerun()

# --- å…¥åŠ›ã‚»ã‚¯ã‚·ãƒ§ãƒ³ ---
if st.session_state.show_input_section:
    col_input, col_button = st.columns([0.8, 0.2])
    with col_input:
        user_query_input = st.text_input(
            "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š",
            value=st.session_state.current_query, 
            placeholder="ä¾‹: ã€Œå¯’ã„ã®ã¯ï¼Ÿã€",
            key="query_input"
        )
    with col_button:
        st.write("") 
        st.write("") 
        search_button = st.button("æ¤œç´¢", key="search_button")

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå…¥åŠ›ã—ãŸå†…å®¹ã‚’ä¿å­˜
    if user_query_input:
        st.session_state.user_entered_query = user_query_input

    if (search_button and user_query_input) or \
       (user_query_input and user_query_input != st.session_state.current_query and st.session_state.get('last_query_input', '') != user_query_input):
        
        st.session_state.current_query = user_query_input
        st.session_state.show_input_section = False 
        st.session_state.last_query_input = user_query_input 
        st.session_state.last_result = None 
        st.session_state.display_node_id = None 
        st.session_state.should_scroll_to_top = True 
        st.rerun() 
    elif search_button and not user_query_input:
        st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ã‹ã‚‰æ¤œç´¢ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")

# --- æ¤œç´¢å‡¦ç†ã¨çµæœã®ä¿å­˜ ---
# current_query ãŒã‚ã‚Šã€ã‹ã¤å…¥åŠ›ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒéè¡¨ç¤ºã®å ´åˆã«æ¤œç´¢å‡¦ç†ã‚’å®Ÿè¡Œ
# ã¾ãŸã€ã¾ã æ¤œç´¢çµæœãŒä¿å­˜ã•ã‚Œã¦ã„ãªã„å ´åˆã«ã®ã¿å®Ÿè¡Œ
if st.session_state.current_query and not st.session_state.show_input_section and st.session_state.last_result is None:
    # ã“ã“ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’è¡¨ç¤º
    st.write(f"ã‚ãªãŸã®è³ªå•: **{st.session_state.user_entered_query}**") # ã“ã“ã‚’ä¿®æ­£
    
    with st.spinner("æƒ…å ±ã‚’æ¤œç´¢ä¸­..."):
        try:
            result = rag_system.query(st.session_state.current_query)
            st.session_state.last_result = result 
            st.session_state.display_node_id = result["selected_question_id"] 
            st.session_state.should_scroll_to_top = True 
            st.rerun() 
        except Exception as e:
            st.error(f"ã‚¯ã‚¨ãƒªå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.session_state.last_result = {"selected_question_id": None, "retrieved_nodes": [], "llm_response_text": f"ã‚¨ãƒ©ãƒ¼: {e}"}
            st.session_state.show_input_section = True 
            st.session_state.should_scroll_to_top = True 
            st.rerun()

# --- ãƒ¡ã‚¤ãƒ³è¡¨ç¤ºã‚¨ãƒªã‚¢ã®ãƒ­ã‚¸ãƒƒã‚¯ ---
if st.session_state.last_result and st.session_state.display_node_id:
    target_node = next((node for node in st.session_state.last_result["retrieved_nodes"] if node.node_id == st.session_state.display_node_id), None)

    if target_node:
        st.markdown(f"**ã‚ãªãŸã®è³ªå•:** `{st.session_state.current_query}`") # ã¾ãŸã¯ user_entered_query
        st.success("âœ¨ è³ªå•ã¨å›ç­”") 
        st.markdown(f"**æ¤œç´¢ã•ã‚ŒãŸè³ªå•å†…å®¹:** \n{target_node.get_content()}")
        st.markdown(f"**å›ç­”:** \n{target_node.metadata.get('answer', 'N/A')}")
        
        image_path = target_node.metadata.get('image', None)
        if image_path and os.path.exists(image_path):
            try:
                st.image(image_path, caption="é–¢é€£ç”»åƒ", width=300)
            except Exception as e:
                st.warning(f"ç”»åƒã®è¡¨ç¤ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        elif image_path:
            st.warning(f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ« '{image_path}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        st.warning(f"ID `{st.session_state.display_node_id}` ã«å¯¾å¿œã™ã‚‹è³ªå•ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    st.divider()

    # --- ãã®ä»–ã®æ¤œç´¢çµæœ ---
    with st.expander("ğŸ” ãã®ä»–ã®æ¤œç´¢çµæœã‚’è¦‹ã‚‹"):
        if st.session_state.last_result and st.session_state.last_result["retrieved_nodes"]:
            for i, node in enumerate(st.session_state.last_result["retrieved_nodes"]):
                if node.node_id == st.session_state.display_node_id:
                    st.markdown(f"**--- ç¾åœ¨è¡¨ç¤ºä¸­ã®è³ªå• (ID: `{node.node_id}`) ---**")
                    st.write(f"è³ªå•: {node.get_content()[:100]}...")
                    st.markdown("---")
                    continue

                st.markdown(f"**--- æ¤œç´¢çµæœ {i+1} (ID: `{node.node_id}`) ---**")
                st.write(f"**è³ªå•:** {node.get_content()}")
                st.write(f"**å›ç­”ã®å†’é ­:** {node.metadata.get('answer', 'N/A')[:100]}...") 
                if node.score is not None:
                    st.write(f"**ã‚¹ã‚³ã‚¢:** {node.score:.4f}")
                
                # ã“ã®è³ªå•ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ãƒœã‚¿ãƒ³
                if st.button(f"ã“ã®è³ªå•ã‚’è¡¨ç¤º (ID: {node.node_id})", key=f"select_node_{node.node_id}"):
                    st.session_state.display_node_id = node.node_id 
                    st.session_state.should_scroll_to_top = True 
                    st.rerun() 
                st.markdown("---")
        else:
            st.info("è¡¨ç¤ºã™ã‚‹ãã®ä»–ã®æ¤œç´¢çµæœã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            
    st.divider()
    # æ–°ã—ã„æ¤œç´¢ã‚’é–‹å§‹ã™ã‚‹ãƒœã‚¿ãƒ³
    st.button("æ–°ã—ã„æ¤œç´¢ã‚’é–‹å§‹ã™ã‚‹", on_click=reset_search)

# --- æ¤œç´¢çµæœãŒãªãã€å…¥åŠ›ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚‚è¡¨ç¤ºã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã€ã‚¨ãƒ©ãƒ¼ã¾ãŸã¯å®Œäº†çŠ¶æ…‹ ---
elif not st.session_state.show_input_section and not st.session_state.current_query and not st.session_state.last_result:
    st.warning("æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    st.button("æ–°ã—ã„æ¤œç´¢ã‚’é–‹å§‹ã™ã‚‹", on_click=reset_search)


st.caption("powered by LlamaIndex & Google Gemini")